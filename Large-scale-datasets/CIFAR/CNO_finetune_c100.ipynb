{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Loading pre-trained model...\n",
      "Loaded pre-trained weights from './vit-t_cifar100_final_290.pth'\n",
      "\n",
      "==> Evaluating loaded pre-trained model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_977253/237511464.py:363: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.load_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Eval | Loss: 1.7478 | Acc: 53.700% (5370/10000)\n",
      "Train Eval | Loss: 1.2415 | Acc: 64.596% (32298/50000)\n",
      "\n",
      "==> Initializing 2 CNO particles...\n",
      "  Initializing particle 1/2...\n",
      "  Initializing particle 2/2...\n",
      "\n",
      "==> Performing initial fitness evaluation (using evaluate_fitness_loss)...\n",
      "  Evaluating initial fitness for particle 1/2:\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2394 | Time: 11.33s\n",
      "  Evaluating initial fitness for particle 2/2:\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2409 | Time: 11.36s\n",
      "\n",
      "Initial Global Best Fitness (particle 1): 1.2394\n",
      "\n",
      "==> Starting CNO Fine-tuning for 10 epochs...\n",
      "\n",
      "--- CNO Epoch 1/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2435 | Time: 28.55s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2405 | Time: 11.30s\n",
      "      Fitness 1.2405 not better than pbest 1.2394\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2405, Current gbest: 1.2394\n",
      "--- CNO Epoch 1 finished. Global Best Fitness: 1.2394 | Time: 42.28s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2479 | Time: 29.44s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2410 | Time: 11.75s\n",
      "      Fitness 1.2410 not better than pbest 1.2409\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2405, Current gbest: 1.2394\n",
      "--- CNO Epoch 1 finished. Global Best Fitness: 1.2394 | Time: 86.00s ---\n",
      "\n",
      "--- CNO Epoch 2/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2432 | Time: 29.74s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2401 | Time: 11.41s\n",
      "      Fitness 1.2401 not better than pbest 1.2394\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2401, Current gbest: 1.2394\n",
      "--- CNO Epoch 2 finished. Global Best Fitness: 1.2394 | Time: 43.70s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2474 | Time: 29.79s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2457 | Time: 11.37s\n",
      "      Fitness 1.2457 not better than pbest 1.2409\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2401, Current gbest: 1.2394\n",
      "--- CNO Epoch 2 finished. Global Best Fitness: 1.2394 | Time: 87.18s ---\n",
      "\n",
      "--- CNO Epoch 3/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2464 | Time: 29.75s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2431 | Time: 11.31s\n",
      "      Fitness 1.2431 not better than pbest 1.2394\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2431, Current gbest: 1.2394\n",
      "--- CNO Epoch 3 finished. Global Best Fitness: 1.2394 | Time: 43.47s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2485 | Time: 29.65s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2387 | Time: 11.78s\n",
      "      New pbest for particle 2: 1.2387 (was 1.2409)\n",
      "Updating gbest...\n",
      "    New Global Best! Fitness: 1.2387 (was 1.2394) from particle 2's pbest\n",
      "--- CNO Epoch 3 finished. Global Best Fitness: 1.2387 | Time: 87.74s ---\n",
      "\n",
      "--- CNO Epoch 4/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2462 | Time: 29.67s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2380 | Time: 11.99s\n",
      "      New pbest for particle 1: 1.2380 (was 1.2394)\n",
      "Updating gbest...\n",
      "    New Global Best! Fitness: 1.2380 (was 1.2387) from particle 1's pbest\n",
      "--- CNO Epoch 4 finished. Global Best Fitness: 1.2380 | Time: 44.24s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2477 | Time: 21.54s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2390 | Time: 11.25s\n",
      "      Fitness 1.2390 not better than pbest 1.2387\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2380, Current gbest: 1.2380\n",
      "--- CNO Epoch 4 finished. Global Best Fitness: 1.2380 | Time: 79.74s ---\n",
      "\n",
      "--- CNO Epoch 5/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2467 | Time: 15.66s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2427 | Time: 11.23s\n",
      "      Fitness 1.2427 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2427, Current gbest: 1.2380\n",
      "--- CNO Epoch 5 finished. Global Best Fitness: 1.2380 | Time: 28.86s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2441 | Time: 15.74s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2420 | Time: 11.34s\n",
      "      Fitness 1.2420 not better than pbest 1.2387\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2420, Current gbest: 1.2380\n",
      "--- CNO Epoch 5 finished. Global Best Fitness: 1.2380 | Time: 58.15s ---\n",
      "\n",
      "--- CNO Epoch 6/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2492 | Time: 15.56s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2410 | Time: 11.37s\n",
      "      Fitness 1.2410 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2410, Current gbest: 1.2380\n",
      "--- CNO Epoch 6 finished. Global Best Fitness: 1.2380 | Time: 28.78s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2417 | Time: 15.70s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2380 | Time: 11.32s\n",
      "      New pbest for particle 2: 1.2380 (was 1.2387)\n",
      "Updating gbest...\n",
      "    New Global Best! Fitness: 1.2380 (was 1.2380) from particle 2's pbest\n",
      "--- CNO Epoch 6 finished. Global Best Fitness: 1.2380 | Time: 57.55s ---\n",
      "\n",
      "--- CNO Epoch 7/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2460 | Time: 15.51s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2386 | Time: 11.28s\n",
      "      Fitness 1.2386 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2386, Current gbest: 1.2380\n",
      "--- CNO Epoch 7 finished. Global Best Fitness: 1.2380 | Time: 28.64s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2502 | Time: 15.70s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2406 | Time: 11.28s\n",
      "      Fitness 1.2406 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2386, Current gbest: 1.2380\n",
      "--- CNO Epoch 7 finished. Global Best Fitness: 1.2380 | Time: 57.42s ---\n",
      "\n",
      "--- CNO Epoch 8/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2406 | Time: 15.49s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2435 | Time: 11.22s\n",
      "      Fitness 1.2435 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2435, Current gbest: 1.2380\n",
      "--- CNO Epoch 8 finished. Global Best Fitness: 1.2380 | Time: 28.61s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2439 | Time: 15.69s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2422 | Time: 11.18s\n",
      "      Fitness 1.2422 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2422, Current gbest: 1.2380\n",
      "--- CNO Epoch 8 finished. Global Best Fitness: 1.2380 | Time: 57.26s ---\n",
      "\n",
      "--- CNO Epoch 9/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2413 | Time: 15.66s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2397 | Time: 11.25s\n",
      "      Fitness 1.2397 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2397, Current gbest: 1.2380\n",
      "--- CNO Epoch 9 finished. Global Best Fitness: 1.2380 | Time: 28.62s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2435 | Time: 15.70s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2431 | Time: 11.49s\n",
      "      Fitness 1.2431 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2397, Current gbest: 1.2380\n",
      "--- CNO Epoch 9 finished. Global Best Fitness: 1.2380 | Time: 57.59s ---\n",
      "\n",
      "--- CNO Epoch 10/10 ---\n",
      "  Processing Particle 1/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2452 | Time: 15.86s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2413 | Time: 11.89s\n",
      "      Fitness 1.2413 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2413, Current gbest: 1.2380\n",
      "--- CNO Epoch 10 finished. Global Best Fitness: 1.2380 | Time: 29.52s ---\n",
      "  Processing Particle 2/2:\n",
      "      Starting 1-epoch SGD (CNO Line 7, η=0.001)... Done. Avg Loss during SGD: 1.2449 | Time: 15.86s\n",
      "      Evaluating fitness (CNO Line 10)... Done. Fitness (Avg Train Loss): 1.2434 | Time: 11.31s\n",
      "      Fitness 1.2434 not better than pbest 1.2380\n",
      "Updating gbest...\n",
      "    No new gbest found this epoch. Best this epoch: 1.2413, Current gbest: 1.2380\n",
      "--- CNO Epoch 10 finished. Global Best Fitness: 1.2380 | Time: 58.48s ---\n",
      "\n",
      "==> Finished CNO Fine-tuning in 687.57 seconds (0.19 hours).\n",
      "\n",
      "==> Evaluating the best model found by CNO...\n",
      "--- Final Training Set Evaluation (using standard evaluate) ---\n",
      "Train Eval | Loss: 1.2420 | Acc: 64.624% (32312/50000)\n",
      "--- Final Test Set Evaluation (using standard evaluate) ---\n",
      "Test  Eval | Loss: 1.7485 | Acc: 53.620% (5362/10000)\n",
      "\n",
      "--- Evaluating Final State of Particle 1/2 ---\n",
      "Particle 1 Train Set Evaluation:\n",
      "P1 Train Eval | Loss: 1.2397 | Acc: 64.742% (32371/50000)\n",
      "Particle 1 Test  Set Evaluation:\n",
      "P1 Test  Eval | Loss: 1.7497 | Acc: 53.690% (5369/10000)\n",
      "\n",
      "--- Evaluating Final State of Particle 2/2 ---\n",
      "Particle 2 Train Set Evaluation:\n",
      "P2 Train Eval | Loss: 1.2394 | Acc: 64.686% (32343/50000)\n",
      "Particle 2 Test  Set Evaluation:\n",
      "P2 Test  Eval | Loss: 1.7508 | Acc: 53.640% (5364/10000)\n",
      "\n",
      "===== Initial Model Performance =====\n",
      "Initial Training Loss: 1.2415\n",
      "Initial Training Acc:  64.596%\n",
      "Initial Test Loss:     1.7478\n",
      "Initial Test Acc:      53.700%\n",
      "====================================\n",
      "\n",
      "===== CNO Fine-tuned Model Performance =====\n",
      "Achieved Global Best Fitness (Min Train Loss during CNO): 1.2380\n",
      "Final Eval Training Loss: 1.2420\n",
      "Final Eval Training Acc:  64.624%\n",
      "Final Eval Test Loss:     1.7485\n",
      "Final Eval Test Acc:      53.620%\n",
      "==========================================\n",
      "==> Saving final CNO best model to ./vit-t_cifar100_cno_ft_290.pth\n",
      "Final best model saved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import copy # For deep copying models and states\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name, num=100):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "# --- ResNet20 Definition (Same as before, omitted for brevity) ---\n",
    "def _weights_init(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd): super().__init__(); self.lambd = lambd\n",
    "    def forward(self, x): return self.lambd(x)\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A': self.shortcut = LambdaLayer(lambda x: F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B': self.shortcut = nn.Sequential(nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(self.expansion * planes))\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out)); out += self.shortcut(x); out = F.relu(out)\n",
    "        return out\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1); layers = []\n",
    "        for stride_val in strides: layers.append(block(self.in_planes, planes, stride_val)); self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x))); out = self.layer1(out); out = self.layer2(out); out = self.layer3(out)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1)); out = out.view(out.size(0), -1); out = self.linear(out)\n",
    "        return out\n",
    "def ResNet20(): return ResNet(BasicBlock, [3, 3, 3], num_classes=100)\n",
    "def ResNet32():\n",
    "    \"\"\" ResNet-32 model configuration based on 6n+2 formula \"\"\"\n",
    "    # (32-2)/6 = 5\n",
    "    return ResNet(BasicBlock, [5, 5, 5], num_classes=100)\n",
    "\n",
    "def ResNet44():\n",
    "    \"\"\" ResNet-44 model configuration based on 6n+2 formula \"\"\"\n",
    "    # (44-2)/6 = 7\n",
    "    return ResNet(BasicBlock, [7, 7, 7], num_classes=100)\n",
    "\n",
    "def ResNet56():\n",
    "    \"\"\" ResNet-56 model configuration based on 6n+2 formula \"\"\"\n",
    "    # (56-2)/6 = 9\n",
    "    return ResNet(BasicBlock, [9, 9, 9], num_classes=100)\n",
    "\n",
    "def ResNet110():\n",
    "    \"\"\" ResNet-110 model configuration based on 6n+2 formula \"\"\"\n",
    "    # (110-2)/6 = 18\n",
    "    return ResNet(BasicBlock, [18, 18, 18], num_classes=100)\n",
    "\n",
    "# -------------------- CNO & Script Parameters --------------------\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR-100 Fine-tuning with CNO on Weights')\n",
    "# --- CNO Parameters (Mapping from image) ---\n",
    "parser.add_argument('--num_particles', default=2, type=int, help='Number of particles (N)')\n",
    "parser.add_argument('--cno_epochs', default=10, type=int, help='Number of CNO iterations (κ_max)')\n",
    "parser.add_argument('--w', default=1, type=float, help='Inertia weight (ω)')\n",
    "parser.add_argument('--c1', default=0.00001, type=float, help='Cognitive learning factor (c1)')\n",
    "parser.add_argument('--c2', default=0.00001, type=float, help='Social learning factor (c2)')\n",
    "parser.add_argument('--eta', default=0.001, type=float, help='Scale factor / Learning rate for inner SGD step (η)') # Map eta to SGD LR\n",
    "# --- Parameters consistent with PSO/SAM for comparison ---\n",
    "parser.add_argument('--initial_noise_level', default=0.0001, type=float, help='Std deviation of noise added to initial particle weights')\n",
    "parser.add_argument('--inner_sgd_momentum', default=0, type=float, help='Momentum for the inner SGD step')\n",
    "parser.add_argument('--inner_sgd_wd', default=5e-4, type=float, help='Weight decay for the inner SGD step')\n",
    "parser.add_argument('--model', default='vit-t', type=str)\n",
    "parser.add_argument('--load_path', default='./vit-t_cifar100_final_290.pth', type=str, help='Path to load the pre-trained model')\n",
    "parser.add_argument('--save_path', default='./vit-t_cifar100_cno_ft_290.pth', type=str, help='Path to save the best model found by CNO')\n",
    "parser.add_argument('--batch_size', default=128, type=int, help='Batch size for SGD training and evaluation')\n",
    "parser.add_argument('--data_path', default='./data', type=str, help='Path to dataset')\n",
    "# --- Use parse_known_args() for Jupyter compatibility ---\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Device Configuration --------------------\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if device == 'cuda':\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# -------------------- 数据准备 --------------------\n",
    "print('==> Preparing data..')\n",
    "cifar100_mean = (0.5071, 0.4867, 0.4408) # CIFAR-100 specific mean\n",
    "cifar100_std = (0.2675, 0.2565, 0.2761)   # CIFAR-100 specific std\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar100_mean, cifar100_std), # <--- MODIFIED to use CIFAR-100 stats\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar100_mean, cifar100_std), # <--- MODIFIED to use CIFAR-100 stats\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100( # <--- MODIFIED\n",
    "    root=args.data_path, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100( # <--- MODIFIED\n",
    "    root=args.data_path, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# -------------------- Loss Function --------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# -------------------- Helper Functions --------------------\n",
    "\n",
    "# Standard evaluation function (for final results)\n",
    "def evaluate(loader, model, set_name=\"Test\"):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    avg_loss = eval_loss / len(loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'{set_name.ljust(5)} Eval | Loss: {avg_loss:.4f} | Acc: {accuracy:.3f}% ({correct}/{total})')\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Function for CNO Line 7: Train ONE SGD epoch and return the *new state* and the loss\n",
    "def train_one_sgd_epoch_and_get_state(initial_state_dict, train_loader, criterion, device, lr, momentum, weight_decay):\n",
    "    # Create a temporary model instance for this SGD step\n",
    "    # model = ResNet20().to(device)\n",
    "    if args.model == 'r20':\n",
    "        model = ResNet20().to(device)\n",
    "    elif args.model == 'r32':\n",
    "        model = ResNet32().to(device)\n",
    "    elif args.model == 'r44':\n",
    "        model = ResNet44().to(device)\n",
    "    elif args.model == 'r56':\n",
    "        model = ResNet56().to(device)\n",
    "    elif args.model == 'r110':\n",
    "        model = ResNet110().to(device)\n",
    "    elif args.model == 'vit-t':\n",
    "        model = VisionTransformer(img_size=32,patch_size=4,num_classes=100, embed_dim=192, depth=12, num_heads=3).to(device)\n",
    "    elif args.model == 'vit-s':\n",
    "        model = VisionTransformer(img_size=32,patch_size=4,num_classes=100, embed_dim=384, depth=12, num_heads=6).to(device)\n",
    "    elif args.model == 'vgg16':\n",
    "        model = VGG('VGG16').to(device)\n",
    "    elif args.model == 'vgg11':\n",
    "        model = VGG('VGG11').to(device)\n",
    "    model.load_state_dict(copy.deepcopy(initial_state_dict)) # Load initial state\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    start_time = time.time()\n",
    "    print(f\"      Starting 1-epoch SGD (CNO Line 7, η={lr})... \", end=\"\")\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Done. Avg Loss during SGD: {avg_loss:.4f} | Time: {epoch_time:.2f}s\")\n",
    "    # Return the state *after* SGD and the loss calculated *during* SGD\n",
    "    return copy.deepcopy(model.state_dict()), avg_loss\n",
    "\n",
    "# Function for CNO Line 10: Evaluate fitness (loss) on train set *without* training\n",
    "def evaluate_fitness_loss(current_state_dict, train_loader, criterion, device):\n",
    "    # model = ResNet20().to(device) # Temporary model\n",
    "    if args.model == 'r20':\n",
    "        model = ResNet20().to(device)\n",
    "    elif args.model == 'r32':\n",
    "        model = ResNet32().to(device)\n",
    "    elif args.model == 'r44':\n",
    "        model = ResNet44().to(device)\n",
    "    elif args.model == 'r56':\n",
    "        model = ResNet56().to(device)\n",
    "    elif args.model == 'r110':\n",
    "        model = ResNet110().to(device)\n",
    "    elif args.model == 'vit-t':\n",
    "        model = VisionTransformer(img_size=32,patch_size=4,num_classes=100, embed_dim=192, depth=12, num_heads=3).to(device)\n",
    "    elif args.model == 'vit-s':\n",
    "        model = VisionTransformer(img_size=32,patch_size=4,num_classes=100, embed_dim=384, depth=12, num_heads=6).to(device)\n",
    "    elif args.model == 'vgg16':\n",
    "        model = VGG('VGG16').to(device)\n",
    "    elif args.model == 'vgg11':\n",
    "        model = VGG('VGG11').to(device)\n",
    "    model.load_state_dict(copy.deepcopy(current_state_dict))\n",
    "    model.eval() # Use eval mode for consistent loss calculation\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    print(f\"      Evaluating fitness (CNO Line 10)... \", end=\"\")\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    avg_loss = total_loss / num_batches\n",
    "    eval_time = time.time() - start_time\n",
    "    print(f\"Done. Fitness (Avg Train Loss): {avg_loss:.4f} | Time: {eval_time:.2f}s\")\n",
    "    return avg_loss\n",
    "\n",
    "# Function to add noise to model parameters\n",
    "def add_noise_to_model(model, noise_level, device):\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            noise = torch.randn_like(param) * noise_level\n",
    "            param.add_(noise.to(device))\n",
    "    return model\n",
    "\n",
    "# Function to initialize particle velocity\n",
    "def initialize_velocity(model):\n",
    "    velocity = {}\n",
    "    with torch.no_grad():\n",
    "      for name, param in model.named_parameters():\n",
    "          if param.requires_grad:\n",
    "              velocity[name] = torch.zeros_like(param)\n",
    "    return velocity\n",
    "\n",
    "# Function for CNO Line 8: Update particle velocity\n",
    "def update_cno_velocity(velocity_dict, z_bar_i_state, pbest_state, gbest_state, w, c1, c2, device):\n",
    "    with torch.no_grad():\n",
    "        for name, param_vel in velocity_dict.items():\n",
    "            if name not in z_i_state: continue # Skip if param not in state (e.g., buffer)\n",
    "\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "\n",
    "            # Ensure all tensors are on the correct device\n",
    "            z_bar_i_param = z_bar_i_state[name].to(device)\n",
    "            pbest_param = pbest_state[name].to(device)\n",
    "            gbest_param = gbest_state[name].to(device)\n",
    "            current_vel = param_vel.to(device)\n",
    "\n",
    "            # CNO Velocity Update (Line 8)\n",
    "            cognitive_term = c1 * r1 * (pbest_param - z_bar_i_param)\n",
    "            social_term = c2 * r2 * (gbest_param - z_bar_i_param)\n",
    "\n",
    "            new_vel = cognitive_term + social_term\n",
    "            velocity_dict[name].copy_(new_vel) # Update velocity in place\n",
    "\n",
    "# Function for CNO Line 9: Update particle position based on velocity\n",
    "# Takes the state *before* SGD (z_i) and adds the *newly computed* velocity\n",
    "def update_particle_position(model_to_update, z_bar_i_state, velocity_dict, device):\n",
    "    new_state = copy.deepcopy(z_bar_i_state) # Start from state before SGD\n",
    "    with torch.no_grad():\n",
    "        for name, param in new_state.items():\n",
    "             if name in velocity_dict:\n",
    "                 param.add_(velocity_dict[name].to(device)) # Add velocity: z_i + v_i\n",
    "    model_to_update.load_state_dict(new_state) # Load the final updated state into the particle's model\n",
    "\n",
    "\n",
    "# -------------------- Load Pre-trained Model --------------------\n",
    "print('==> Loading pre-trained model...')\n",
    "# initial_model = ResNet20().to(device)\n",
    "if args.model == 'r20':\n",
    "    initial_model = ResNet20().to(device)\n",
    "elif args.model == 'r32':\n",
    "    initial_model = ResNet32().to(device)\n",
    "elif args.model == 'r44':\n",
    "    initial_model = ResNet44().to(device)\n",
    "elif args.model == 'r56':\n",
    "    initial_model = ResNet56().to(device)\n",
    "elif args.model == 'r110':\n",
    "    initial_model = ResNet110().to(device)\n",
    "elif args.model == 'vit-t':\n",
    "    initial_model = VisionTransformer(img_size=32,patch_size=4,num_classes=100, embed_dim=192, depth=12, num_heads=3).to(device)\n",
    "elif args.model == 'vit-s':\n",
    "    initial_model = VisionTransformer(img_size=32,patch_size=4,num_classes=100, embed_dim=384, depth=12, num_heads=6).to(device)\n",
    "elif args.model == 'vgg16':\n",
    "    initial_model = VGG('VGG16').to(device)\n",
    "elif args.model == 'vgg11':\n",
    "    initial_model = VGG('VGG11').to(device)\n",
    "\n",
    "\n",
    "if os.path.exists(args.load_path):\n",
    "    try:\n",
    "        checkpoint = torch.load(args.load_path, map_location=device)\n",
    "        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint: initial_model.load_state_dict(checkpoint['state_dict'])\n",
    "        elif isinstance(checkpoint, dict): initial_model.load_state_dict(checkpoint)\n",
    "        else: initial_model = checkpoint\n",
    "        print(f\"Loaded pre-trained weights from '{args.load_path}'\")\n",
    "    except Exception as e: print(f\"Error loading checkpoint: {e}. Exiting.\"); exit()\n",
    "else: print(f\"Pre-trained model file not found at '{args.load_path}'. Exiting.\"); exit()\n",
    "\n",
    "# Evaluate the loaded model once (using standard evaluate)\n",
    "print(\"\\n==> Evaluating loaded pre-trained model:\")\n",
    "initial_test_loss, initial_test_acc = evaluate(testloader, initial_model, \"Test\")\n",
    "# We need initial train loss for comparison, evaluate it here\n",
    "initial_train_loss, initial_train_acc = evaluate(trainloader, initial_model, \"Train\")\n",
    "\n",
    "\n",
    "# -------------------- CNO Initialization --------------------\n",
    "print(f\"\\n==> Initializing {args.num_particles} CNO particles...\")\n",
    "particles = []\n",
    "gbest_state_dict = None # Will be set after initial eval\n",
    "gbest_fitness = float('inf')\n",
    "\n",
    "for i in range(args.num_particles):\n",
    "    print(f\"  Initializing particle {i+1}/{args.num_particles}...\")\n",
    "    particle_model = copy.deepcopy(initial_model).to(device)\n",
    "    if i > 0 or args.num_particles == 1: # Add noise to copies\n",
    "         particle_model = add_noise_to_model(particle_model, args.initial_noise_level, device)\n",
    "\n",
    "    velocity = initialize_velocity(particle_model)\n",
    "    pbest_state_dict = copy.deepcopy(particle_model.state_dict()) # Initial pbest is initial state\n",
    "    pbest_fitness = float('inf') # Will be set by initial eval\n",
    "\n",
    "    particles.append({\n",
    "        'id': i,\n",
    "        'model': particle_model, # Holds the current position z_i\n",
    "        'velocity': velocity,\n",
    "        'pbest_state_dict': pbest_state_dict,\n",
    "        'pbest_fitness': pbest_fitness,\n",
    "        'current_fitness': float('inf')\n",
    "    })\n",
    "\n",
    "# --- Initial Fitness Evaluation (Crucial for CNO/PSO) ---\n",
    "print(\"\\n==> Performing initial fitness evaluation (using evaluate_fitness_loss)...\")\n",
    "current_epoch_best_fitness = float('inf')\n",
    "current_epoch_best_particle_idx = -1\n",
    "\n",
    "for i, particle in enumerate(particles):\n",
    "    print(f\"  Evaluating initial fitness for particle {i+1}/{args.num_particles}:\")\n",
    "    # Evaluate fitness of the initial state z_i\n",
    "    fitness = evaluate_fitness_loss(\n",
    "        particle['model'].state_dict(), trainloader, criterion, device\n",
    "    )\n",
    "    particle['current_fitness'] = fitness\n",
    "    particle['pbest_fitness'] = fitness # Initial pbest fitness is the initial fitness\n",
    "    # pbest_state_dict is already set to the initial state\n",
    "\n",
    "    # Check if this particle is the best *so far* in this initial eval\n",
    "    if fitness < current_epoch_best_fitness:\n",
    "        current_epoch_best_fitness = fitness\n",
    "        current_epoch_best_particle_idx = i\n",
    "\n",
    "# Update global best (gbest) based on the initial evaluation\n",
    "if current_epoch_best_particle_idx != -1 :\n",
    "     initial_best_particle = particles[current_epoch_best_particle_idx]\n",
    "     print(f\"\\nInitial Global Best Fitness (particle {current_epoch_best_particle_idx+1}): {current_epoch_best_fitness:.4f}\")\n",
    "     gbest_fitness = current_epoch_best_fitness\n",
    "     gbest_state_dict = copy.deepcopy(initial_best_particle['pbest_state_dict']) # Use its pbest state\n",
    "else:\n",
    "     print(\"\\nWarning: No valid fitness found in initial evaluation.\")\n",
    "     # Fallback: use the originally loaded model as gbest\n",
    "     gbest_fitness = evaluate_fitness_loss(initial_model.state_dict(), trainloader, criterion, device)\n",
    "     gbest_state_dict = copy.deepcopy(initial_model.state_dict())\n",
    "     print(f\"Using loaded model as initial gbest (Fitness: {gbest_fitness:.4f})\")\n",
    "\n",
    "\n",
    "# -------------------- CNO Main Loop --------------------\n",
    "print(f\"\\n==> Starting CNO Fine-tuning for {args.cno_epochs} epochs...\")\n",
    "cno_start_time = time.time()\n",
    "\n",
    "for cno_epoch in range(args.cno_epochs):\n",
    "    print(f\"\\n--- CNO Epoch {cno_epoch + 1}/{args.cno_epochs} ---\")\n",
    "    epoch_start_time = time.time()\n",
    "    current_epoch_best_fitness = float('inf')\n",
    "    current_epoch_best_particle_idx = -1\n",
    "\n",
    "    for i, particle in enumerate(particles):\n",
    "        print(f\"  Processing Particle {i+1}/{args.num_particles}:\")\n",
    "\n",
    "        # --- Store current state z_i ---\n",
    "        z_i_state = copy.deepcopy(particle['model'].state_dict())\n",
    "\n",
    "        # --- CNO Line 7: Perform SGD step ---\n",
    "        # Gets state *after* SGD (z_bar_i) and the loss *during* that SGD run\n",
    "        z_bar_i_state, sgd_run_loss = train_one_sgd_epoch_and_get_state(\n",
    "            z_i_state, trainloader, criterion, device,\n",
    "            args.eta, args.inner_sgd_momentum, args.inner_sgd_wd\n",
    "        )\n",
    "\n",
    "        new_state = copy.deepcopy(z_bar_i_state)\n",
    "        particle['model'].load_state_dict(new_state)\n",
    "        # --- CNO Line 10: Evaluate Fitness of the *new* position z_i ---\n",
    "        current_fitness = evaluate_fitness_loss(\n",
    "            particle['model'].state_dict(), trainloader, criterion, device\n",
    "        )\n",
    "        particle['current_fitness'] = current_fitness\n",
    "\n",
    "        # --- CNO Lines 11-13: Update PBest ---\n",
    "        if current_fitness < particle['pbest_fitness']:\n",
    "            print(f\"      New pbest for particle {i+1}: {current_fitness:.4f} (was {particle['pbest_fitness']:.4f})\")\n",
    "            particle['pbest_fitness'] = current_fitness\n",
    "            particle['pbest_state_dict'] = copy.deepcopy(particle['model'].state_dict())\n",
    "        else:\n",
    "            print(f\"      Fitness {current_fitness:.4f} not better than pbest {particle['pbest_fitness']:.4f}\")\n",
    "\n",
    "        # Track best particle *in this epoch* based on fitness evaluated at Line 10\n",
    "        if current_fitness < current_epoch_best_fitness:\n",
    "             current_epoch_best_fitness = current_fitness\n",
    "             current_epoch_best_particle_idx = i\n",
    "\n",
    "        # --- CNO Lines 14-16: Update GBest (after processing all particles) ---\n",
    "        print(\"Updating gbest...\")\n",
    "        if current_epoch_best_particle_idx != -1 and current_epoch_best_fitness < gbest_fitness:\n",
    "            print(f\"    New Global Best! Fitness: {current_epoch_best_fitness:.4f} (was {gbest_fitness:.4f}) from particle {current_epoch_best_particle_idx+1}'s pbest\")\n",
    "            gbest_fitness = current_epoch_best_fitness\n",
    "            # Gbest state comes from the pbest state of the particle that achieved the best fitness *in this epoch*\n",
    "            gbest_state_dict = copy.deepcopy(particles[current_epoch_best_particle_idx]['pbest_state_dict'])\n",
    "        else:\n",
    "            print(f\"    No new gbest found this epoch. Best this epoch: {current_epoch_best_fitness:.4f}, Current gbest: {gbest_fitness:.4f}\")\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"--- CNO Epoch {cno_epoch + 1} finished. Global Best Fitness: {gbest_fitness:.4f} | Time: {epoch_time:.2f}s ---\")\n",
    "\n",
    "        # --- CNO Line 8: Update Velocity ---\n",
    "        update_cno_velocity(\n",
    "            particle['velocity'],\n",
    "            z_bar_i_state,       # State after SGD\n",
    "            particle['pbest_state_dict'],\n",
    "            gbest_state_dict,\n",
    "            args.w, args.c1, args.c2, device\n",
    "        )\n",
    "\n",
    "        # --- CNO Line 9: Update Position ---\n",
    "        # Applies z_i + v_i to the particle's model\n",
    "        update_particle_position(\n",
    "             particle['model'], # Model to update\n",
    "             z_bar_i_state,         # State before SGD (z_i)\n",
    "             particle['velocity'], # Newly computed velocity (v_i)\n",
    "             device\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "total_cno_time = time.time() - cno_start_time\n",
    "print(f\"\\n==> Finished CNO Fine-tuning in {total_cno_time:.2f} seconds ({total_cno_time/3600:.2f} hours).\")\n",
    "\n",
    "# -------------------- Final Evaluation --------------------\n",
    "print(\"\\n==> Evaluating the best model found by CNO...\")\n",
    "# final_best_model = ResNet20().to(device)\n",
    "if args.model == 'r20':\n",
    "    final_best_model = ResNet20().to(device)\n",
    "elif args.model == 'r32':\n",
    "    final_best_model = ResNet32().to(device)\n",
    "elif args.model == 'r44':\n",
    "    final_best_model = ResNet44().to(device)\n",
    "elif args.model == 'r56':\n",
    "    final_best_model = ResNet56().to(device)\n",
    "elif args.model == 'r110':\n",
    "    final_best_model = ResNet110().to(device)\n",
    "elif args.model == 'vit-t':\n",
    "    final_best_model = VisionTransformer(img_size=32,patch_size=4,num_classes=100, embed_dim=192, depth=12, num_heads=3).to(device)\n",
    "elif args.model == 'vit-s':\n",
    "    final_best_model = VisionTransformer(img_size=32,patch_size=4,num_classes=100, embed_dim=384, depth=12, num_heads=6).to(device)\n",
    "elif args.model == 'vgg16':\n",
    "    final_best_model = VGG('VGG16').to(device)\n",
    "elif args.model == 'vgg11':\n",
    "    final_best_model = VGG('VGG11').to(device)\n",
    "if gbest_state_dict is not None:\n",
    "    final_best_model.load_state_dict(gbest_state_dict)\n",
    "else:\n",
    "    print(\"Error: Global best state dictionary was not set. Cannot evaluate.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "print(\"--- Final Training Set Evaluation (using standard evaluate) ---\")\n",
    "final_train_loss, final_train_acc = evaluate(trainloader, final_best_model, \"Train\")\n",
    "\n",
    "print(\"--- Final Test Set Evaluation (using standard evaluate) ---\")\n",
    "final_test_loss, final_test_acc = evaluate(testloader, final_best_model, \"Test\")\n",
    "\n",
    "\n",
    "particle_eval_results = {} # Optional: dictionary to store results per particle\n",
    "for i, particle in enumerate(particles):\n",
    "    print(f\"\\n--- Evaluating Final State of Particle {i+1}/{args.num_particles} ---\")\n",
    "    # The model in particle['model'] holds the final state after all updates\n",
    "    particle_model = particle['model']\n",
    "\n",
    "    # Use standard evaluate for training set\n",
    "    print(f\"Particle {i+1} Train Set Evaluation:\")\n",
    "    train_loss, train_acc = evaluate(trainloader, particle_model, f\"P{i+1} Train\")\n",
    "\n",
    "    # Use standard evaluate for test set\n",
    "    print(f\"Particle {i+1} Test  Set Evaluation:\") # Added padding for alignment\n",
    "    test_loss, test_acc = evaluate(testloader, particle_model, f\"P{i+1} Test \")\n",
    "\n",
    "    particle_eval_results[f'particle_{i+1}'] = {'train_loss': train_loss, 'train_acc': train_acc, 'test_loss': test_loss, 'test_acc': test_acc}\n",
    "\n",
    "print(\"\\n===== Initial Model Performance =====\")\n",
    "print(f\"Initial Training Loss: {initial_train_loss:.4f}\") # From evaluate() at start\n",
    "print(f\"Initial Training Acc:  {initial_train_acc:.3f}%\")\n",
    "print(f\"Initial Test Loss:     {initial_test_loss:.4f}\")\n",
    "print(f\"Initial Test Acc:      {initial_test_acc:.3f}%\")\n",
    "print(\"====================================\")\n",
    "\n",
    "print(\"\\n===== CNO Fine-tuned Model Performance =====\")\n",
    "print(f\"Achieved Global Best Fitness (Min Train Loss during CNO): {gbest_fitness:.4f}\")\n",
    "print(f\"Final Eval Training Loss: {final_train_loss:.4f}\") # From evaluate() at end\n",
    "print(f\"Final Eval Training Acc:  {final_train_acc:.3f}%\")\n",
    "print(f\"Final Eval Test Loss:     {final_test_loss:.4f}\")\n",
    "print(f\"Final Eval Test Acc:      {final_test_acc:.3f}%\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "# -------------------- Save Final Model --------------------\n",
    "print(f'==> Saving final CNO best model to {args.save_path}')\n",
    "save_dir = os.path.dirname(args.save_path)\n",
    "if save_dir and not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if gbest_state_dict is not None:\n",
    "    torch.save(gbest_state_dict, args.save_path)\n",
    "    print(\"Final best model saved.\")\n",
    "else:\n",
    "    print(\"Error: Global best state dictionary was not set. Model not saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sulw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
